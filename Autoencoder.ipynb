{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definir la arquitectura del Autoencoder Convolucional\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            # Primera capa conv: 3 -> 32 canales\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 128 -> 64\n",
    "            \n",
    "            # Segunda capa conv: 32 -> 64 canales\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 64 -> 32\n",
    "            \n",
    "            # Tercera capa conv: 64 -> 128 canales\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 32 -> 16\n",
    "            \n",
    "            # Cuarta capa conv: 128 -> 256 canales\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)   # 16 -> 8\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            # Primera capa deconv: 256 -> 128 canales\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Segunda capa deconv: 128 -> 64 canales\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Tercera capa deconv: 64 -> 32 canales\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Cuarta capa deconv: 32 -> 3 canales\n",
    "            nn.ConvTranspose2d(32, 3, kernel_size=2, stride=2),\n",
    "            nn.Sigmoid()  # Normalizar salida entre 0 y 1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Dataset personalizado para cargar imágenes de rostros\n",
    "class FaceDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(root_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.image_files[idx])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image\n",
    "\n",
    "# Configuración de transformaciones para las imágenes\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Redimensionar a 128x128\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Función de entrenamiento\n",
    "def train_autoencoder(model, train_loader, num_epochs, device):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch_idx, data in enumerate(train_loader):\n",
    "            img = data.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            output = model(img)\n",
    "            loss = criterion(output, img)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            if (batch_idx + 1) % 10 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], '\n",
    "                      f'Loss: {loss.item():.6f}')\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.6f}')\n",
    "\n",
    "# Función para visualizar resultados\n",
    "def visualize_results(model, dataset, num_images=5, device='cuda'):\n",
    "    model.eval()\n",
    "    dataloader = DataLoader(dataset, batch_size=num_images, shuffle=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        images = next(iter(dataloader))\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Mostrar imágenes originales y reconstruidas\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        for i in range(num_images):\n",
    "            # Imagen original\n",
    "            plt.subplot(2, num_images, i + 1)\n",
    "            plt.imshow(images[i].cpu().permute(1, 2, 0))\n",
    "            plt.axis('off')\n",
    "            if i == 0:\n",
    "                plt.title('Original')\n",
    "            \n",
    "            # Imagen reconstruida\n",
    "            plt.subplot(2, num_images, i + num_images + 1)\n",
    "            plt.imshow(outputs[i].cpu().permute(1, 2, 0))\n",
    "            plt.axis('off')\n",
    "            if i == 0:\n",
    "                plt.title('Reconstruida')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Uso del modelo\n",
    "def main():\n",
    "    # Configurar dispositivo\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "    # Crear el dataset (ajusta el path a tu directorio de imágenes)\n",
    "    dataset = FaceDataset(root_dir='path/to/face/images', transform=transform)\n",
    "    train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    # Inicializar y mover el modelo al dispositivo\n",
    "    model = ConvAutoencoder().to(device)\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    train_autoencoder(model, train_loader, num_epochs=50, device=device)\n",
    "\n",
    "    # Visualizar resultados\n",
    "    visualize_results(model, dataset, device=device)\n",
    "\n",
    "    # Guardar el modelo\n",
    "    torch.save(model.state_dict(), 'face_autoencoder.pth')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
