{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "import os\n",
    "\n",
    "\n",
    "# Flags y rutas\n",
    "isGcloud = False  # Cambiar a True para usar Google Drive\n",
    "\n",
    "# Definición de rutas\n",
    "if isGcloud:\n",
    "    from google.colab import drive\n",
    "    # Montar Google Drive\n",
    "    drive.mount('/content/drive')\n",
    "    BASE_PATH = '/content/drive/MyDrive/ML2'  # Ruta base en Drive\n",
    "else:\n",
    "    BASE_PATH = '~/eric/BEGAN'  # Ruta base local\n",
    "    DATASET_PATH = '~/datasets'\n",
    "\n",
    "# Crear directorios necesarios\n",
    "PATHS = {\n",
    "    'data': os.path.join(DATASET_PATH, 'lfw'),\n",
    "    'models': os.path.join(BASE_PATH, 'models'),\n",
    "    'results': os.path.join(BASE_PATH, 'results')\n",
    "}\n",
    "\n",
    "for path in PATHS.values():\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "# Hyperparameters optimizados\n",
    "latent_size = 128\n",
    "hidden_size = 128  # Aumentado de 64 a 128\n",
    "image_size = 64\n",
    "lambda_k = 0.001\n",
    "gamma = 0.7  # Aumentado de 0.5 a 0.7\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "\n",
    "# Aumentar el tamaño de las capas ocultas\n",
    "hidden_size = 256  # En lugar de 128\n",
    "\n",
    "# Ajustar los hiperparámetros de equilibrio\n",
    "gamma = 0.8  # Aumentado de 0.7\n",
    "lambda_k = 0.0015  # Aumentado de 0.001\n",
    "\n",
    "# Aumentar el tamaño del batch para mayor estabilidad\n",
    "batch_size = 64  # En lugar de 32\n",
    "\n",
    "class Reshape(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(-1, *self.shape)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_size, hidden_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_size, 8 * 8 * hidden_size),\n",
    "            nn.BatchNorm1d(8 * 8 * hidden_size),\n",
    "            nn.ReLU(True),\n",
    "            Reshape((hidden_size, 8, 8)),\n",
    "            nn.ConvTranspose2d(hidden_size, hidden_size, 3, 2, 1, 1),\n",
    "            nn.BatchNorm2d(hidden_size),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(hidden_size, hidden_size, 3, 2, 1, 1),\n",
    "            nn.BatchNorm2d(hidden_size),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(hidden_size, hidden_size, 3, 2, 1, 1),\n",
    "            nn.BatchNorm2d(hidden_size),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(hidden_size, 3, 3, 1, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "# class Generator(nn.Module):\n",
    "#     def __init__(self, latent_size, hidden_size):\n",
    "#         super(Generator, self).__init__()\n",
    "#         self.decoder = nn.Sequential(\n",
    "#             nn.Linear(latent_size, 8 * 8 * hidden_size),\n",
    "#             nn.BatchNorm1d(8 * 8 * hidden_size),\n",
    "#             nn.LeakyReLU(0.2, True),  # Cambiar ReLU por LeakyReLU\n",
    "#             Reshape((hidden_size, 8, 8)),\n",
    "            \n",
    "#             # Añadir más capas convolucionales\n",
    "#             nn.ConvTranspose2d(hidden_size, hidden_size, 3, 2, 1, 1),\n",
    "#             nn.BatchNorm2d(hidden_size),\n",
    "#             nn.LeakyReLU(0.2, True),\n",
    "#             nn.Conv2d(hidden_size, hidden_size, 3, 1, 1),  # Capa adicional\n",
    "#             nn.BatchNorm2d(hidden_size),\n",
    "#             nn.LeakyReLU(0.2, True),\n",
    "            \n",
    "#             nn.ConvTranspose2d(hidden_size, hidden_size//2, 3, 2, 1, 1),\n",
    "#             nn.BatchNorm2d(hidden_size//2),\n",
    "#             nn.LeakyReLU(0.2, True),\n",
    "#             nn.Conv2d(hidden_size//2, hidden_size//2, 3, 1, 1),  # Capa adicional\n",
    "#             nn.BatchNorm2d(hidden_size//2),\n",
    "#             nn.LeakyReLU(0.2, True),\n",
    "            \n",
    "#             nn.ConvTranspose2d(hidden_size//2, hidden_size//4, 3, 2, 1, 1),\n",
    "#             nn.BatchNorm2d(hidden_size//4),\n",
    "#             nn.LeakyReLU(0.2, True),\n",
    "            \n",
    "#             nn.Conv2d(hidden_size//4, 3, 3, 1, 1),\n",
    "#             nn.Tanh()\n",
    "#         )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, hidden_size, 3, 2, 1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(hidden_size, hidden_size * 2, 3, 2, 1),\n",
    "            nn.BatchNorm2d(hidden_size * 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(hidden_size * 2, hidden_size * 4, 3, 2, 1),\n",
    "            nn.BatchNorm2d(hidden_size * 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(hidden_size * 4, hidden_size * 8, 3, 2, 1),\n",
    "            nn.BatchNorm2d(hidden_size * 8),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(hidden_size * 8, hidden_size * 4, 3, 2, 1, 1),\n",
    "            nn.BatchNorm2d(hidden_size * 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(hidden_size * 4, hidden_size * 2, 3, 2, 1, 1),\n",
    "            nn.BatchNorm2d(hidden_size * 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(hidden_size * 2, hidden_size, 3, 2, 1, 1),\n",
    "            nn.BatchNorm2d(hidden_size),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(hidden_size, 3, 3, 2, 1, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "def save_checkpoint(state, filename):\n",
    "    torch.save(state, filename)\n",
    "    if isGcloud:\n",
    "        print(f\"Checkpoint guardado en Google Drive: {filename}\")\n",
    "    else:\n",
    "        print(f\"Checkpoint guardado localmente: {filename}\")\n",
    "\n",
    "def load_checkpoint(filename, generator, discriminator, g_optimizer, d_optimizer):\n",
    "    if os.path.exists(filename):\n",
    "        checkpoint = torch.load(filename)\n",
    "        generator.load_state_dict(checkpoint['generator_state_dict'])\n",
    "        discriminator.load_state_dict(checkpoint['discriminator_state_dict'])\n",
    "        g_optimizer.load_state_dict(checkpoint['g_optimizer_state_dict'])\n",
    "        d_optimizer.load_state_dict(checkpoint['d_optimizer_state_dict'])\n",
    "        return checkpoint['epoch'], checkpoint['k'], checkpoint['M_global']\n",
    "    return 0, 0.5, None  # Inicializar k en 0.5 en lugar de 0.0\n",
    "\n",
    "def train_began(latent_size, hidden_size, image_size, lambda_k, gamma, batch_size, num_epochs):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.CenterCrop(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    dataset = torchvision.datasets.LFWPeople(\n",
    "        root=PATHS['data'],\n",
    "        split='train',\n",
    "        transform=transform,\n",
    "        download=True\n",
    "    )\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    generator = Generator(latent_size, hidden_size).to(device)\n",
    "    discriminator = Discriminator(hidden_size).to(device)\n",
    "\n",
    "    g_optimizer = optim.Adam(generator.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "    d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "\n",
    "    checkpoint_path = os.path.join(PATHS['models'], 'began_checkpoint.pth')\n",
    "    start_epoch, k, M_global = load_checkpoint(\n",
    "        checkpoint_path, generator, discriminator, g_optimizer, d_optimizer\n",
    "    )\n",
    "\n",
    "    if k == 0.5:  # Si no se cargó checkpoint\n",
    "        M_global = None\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        for i, (real_images, _) in enumerate(dataloader):\n",
    "            batch_size = real_images.size(0)\n",
    "            real_images = real_images.to(device)\n",
    "\n",
    "            # Train discriminator\n",
    "            d_optimizer.zero_grad()\n",
    "\n",
    "            d_real = discriminator(real_images)\n",
    "            d_real_loss = torch.mean(torch.abs(real_images - d_real))\n",
    "\n",
    "            z = torch.randn(batch_size, latent_size).to(device)\n",
    "            fake_images = generator(z)\n",
    "            d_fake = discriminator(fake_images.detach())\n",
    "            g_loss = torch.mean(torch.abs(fake_images.detach() - d_fake))\n",
    "\n",
    "            d_loss = d_real_loss - k * g_loss  # Modificado: usando g_loss en lugar de d_fake_loss\n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "\n",
    "            # Train generator\n",
    "            g_optimizer.zero_grad()\n",
    "            d_fake = discriminator(fake_images)\n",
    "            g_loss = torch.mean(torch.abs(fake_images - d_fake))\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "\n",
    "            # Update k - modificado\n",
    "            balance = (gamma * d_real_loss - g_loss).item()\n",
    "            k = k + lambda_k * balance\n",
    "            k = min(max(k, 0), 1)\n",
    "\n",
    "            # Update convergence measure\n",
    "            M_global = d_real_loss.item() + abs(balance)\n",
    "\n",
    "            if i % 100 == 0:  # Aumentada frecuencia de visualización\n",
    "                print(f'Epoch [{epoch}/{num_epochs}] Step [{i}/{len(dataloader)}] '\n",
    "                      f'd_loss: {d_loss.item():.4f} g_loss: {g_loss.item():.4f} '\n",
    "                      f'M: {M_global:.4f} k: {k:.4f}')\n",
    "\n",
    "                results_path = os.path.join(PATHS['results'], f'fake_images_epoch_{epoch}_step_{i}.png')\n",
    "                vutils.save_image(fake_images.data[:16], results_path, normalize=True, nrow=4)\n",
    "\n",
    "                fig, ax = plt.subplots(3, 4, figsize=(12, 8))\n",
    "                for j in range(4):\n",
    "                    real_img = (real_images[j].cpu().detach().permute(1,2,0) + 1) / 2\n",
    "                    recon_img = (d_real[j].cpu().detach().permute(1,2,0) + 1) / 2\n",
    "                    fake_img = (fake_images[j].cpu().detach().permute(1,2,0) + 1) / 2\n",
    "\n",
    "                    real_img = torch.clamp(real_img, 0, 1)\n",
    "                    recon_img = torch.clamp(recon_img, 0, 1)\n",
    "                    fake_img = torch.clamp(fake_img, 0, 1)\n",
    "\n",
    "                    ax[0,j].imshow(real_img)\n",
    "                    ax[0,j].axis('off')\n",
    "                    if j == 0: ax[0,j].set_title('Real')\n",
    "\n",
    "                    ax[1,j].imshow(recon_img)\n",
    "                    ax[1,j].axis('off')\n",
    "                    if j == 0: ax[1,j].set_title('Reconstructed')\n",
    "\n",
    "                    ax[2,j].imshow(fake_img)\n",
    "                    ax[2,j].axis('off')\n",
    "                    if j == 0: ax[2,j].set_title('Generated')\n",
    "\n",
    "                plt.tight_layout()\n",
    "                comparison_path = os.path.join(PATHS['results'], f'comparison_epoch_{epoch}_step_{i}.png')\n",
    "                plt.savefig(comparison_path)\n",
    "                plt.close()\n",
    "\n",
    "        checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'generator_state_dict': generator.state_dict(),\n",
    "            'discriminator_state_dict': discriminator.state_dict(),\n",
    "            'g_optimizer_state_dict': g_optimizer.state_dict(),\n",
    "            'd_optimizer_state_dict': d_optimizer.state_dict(),\n",
    "            'k': k,\n",
    "            'M_global': M_global\n",
    "        }\n",
    "        save_checkpoint(checkpoint, checkpoint_path)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
