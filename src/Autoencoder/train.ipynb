{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import tqdm\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "\n",
    "# Obtener la ruta de src\n",
    "src_path = '/home/eric/ml2/src'\n",
    "sys.path.append(src_path)\n",
    "import utils.lfw_dataset_handler as lfw\n",
    "import paths_config as paths\n",
    "# import src.paths_config as paths\n",
    "\n",
    "\n",
    "# Definir modelo\n",
    "\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Autoencoder Convolucional para Rostros\n",
    "    =====================================\n",
    "    \n",
    "    Arquitectura del modelo:\n",
    "    \n",
    "    Encoder:\n",
    "    --------\n",
    "    1. Input (3, 128, 128) -> Conv2d -> (32, 64, 64)   [Reducción espacial: 128->64]\n",
    "    2. (32, 64, 64) -> Conv2d -> (64, 32, 32)          [Reducción espacial: 64->32]\n",
    "    3. (64, 32, 32) -> Conv2d -> (128, 16, 16)         [Reducción espacial: 32->16]\n",
    "    4. (128, 16, 16) -> Conv2d -> (256, 8, 8)          [Reducción espacial: 16->8]\n",
    "    \n",
    "    La dimensión del espacio latente es: 256 * 8 * 8 = 16,384\n",
    "    \n",
    "    Decoder:\n",
    "    --------\n",
    "    Proceso inverso usando ConvTranspose2d para upsampling\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(32, 3, kernel_size=2, stride=2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass del modelo.\n",
    "        \n",
    "        Proceso:\n",
    "        1. La imagen pasa por el encoder -> representación comprimida\n",
    "        2. La representación comprimida pasa por el decoder -> reconstrucción\n",
    "        \"\"\"\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"\n",
    "    Entrena el modelo por un epoch\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo a entrenar\n",
    "        dataloader: DataLoader con los datos de entrenamiento\n",
    "        criterion: Función de pérdida\n",
    "        optimizer: Optimizador\n",
    "        device: Dispositivo de cómputo\n",
    "    \n",
    "    Returns:\n",
    "        float: Pérdida promedio del epoch\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch, _ in tqdm(dataloader, desc='Training', leave=False):\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch)\n",
    "        loss = criterion(outputs, batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(dataloader)\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    \"\"\"\n",
    "    Evalúa el modelo en el conjunto de validación\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo a evaluar\n",
    "        dataloader: DataLoader con los datos de validación\n",
    "        criterion: Función de pérdida\n",
    "        device: Dispositivo de cómputo\n",
    "\n",
    "    Returns:\n",
    "        float: Pérdida promedio en el conjunto de validación\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch, _ in tqdm(dataloader, desc=\"Validating\"):  # Ignoramos las etiquetas\n",
    "            batch = batch.to(device)\n",
    "            outputs = model(batch)\n",
    "            loss = criterion(outputs, batch)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, loss, is_best=False, checkpoint_dir='./checkpoints'):\n",
    "    \"\"\"\n",
    "    Guarda un checkpoint del modelo\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo a guardar\n",
    "        optimizer: Optimizador\n",
    "        epoch: Número de epoch\n",
    "        loss: Pérdida\n",
    "        is_best: Si es el mejor modelo\n",
    "        checkpoint_dir: Directorio para guardar el checkpoint\n",
    "    \"\"\"\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss\n",
    "    }\n",
    "    \n",
    "    checkpoint_path = f\"{checkpoint_dir}/checkpoint_{epoch}.pth\"\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    \n",
    "    if is_best:\n",
    "        best_path = f\"{checkpoint_dir}/best_model.pth\"\n",
    "        torch.save(checkpoint, best_path)\n",
    "\n",
    "def train(model, train_loader, val_loader, criterion, optimizer, device, epochs=10, checkpoint_freq=5):\n",
    "    \"\"\"\n",
    "    Entrena el modelo\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo a entrenar\n",
    "        train_loader: DataLoader con los datos de entrenamiento\n",
    "        val_loader: DataLoader con los datos de validación\n",
    "        criterion: Función de pérdida\n",
    "        optimizer: Optimizador\n",
    "        device: Dispositivo de cómputo\n",
    "        epochs: Número de epochs\n",
    "        checkpoint_freq: Frecuencia para guardar checkpoints\n",
    "    \"\"\"\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss = validate(model, val_loader, criterion, device)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs} => Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "        \n",
    "        if (epoch + 1) % checkpoint_freq == 0:\n",
    "            save_checkpoint(model, optimizer, epoch, val_loss,checkpoint_dir=paths.AUTOENCODER_CHECKPOINT_DIR)\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            save_checkpoint(model, optimizer, epoch, val_loss, is_best=True, checkpoint_dir=paths.AUTOENCODER_CHECKPOINT_DIR)\n",
    "\n",
    "    # save final model\n",
    "    save_checkpoint(model, optimizer, epoch, val_loss, is_best=False, checkpoint_dir=paths.AUTOENCODER_MODEL_DIR) \n",
    "    print(\"Training complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Dataset lfw encontrado en disco.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eric/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:128: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m     train(model, train_loader, val_loader, criterion, optimizer, device, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, checkpoint_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 31\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 28\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Entrenar modelo\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, device, epochs, checkpoint_freq)\u001b[0m\n\u001b[1;32m    179\u001b[0m best_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m--> 181\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m validate(model, val_loader, criterion, device)\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m => Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 104\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, dataloader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m    102\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    103\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m--> 104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTraining\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m:\n\u001b[1;32m    105\u001b[0m     batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    106\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "\n",
    "def main():\n",
    "    # Configurar ruta de datos\n",
    "    paths.setup_autoencoder_paths()\n",
    "    # Configurar dispositivo\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Definir transformaciones\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    # Obtener dataloaders\n",
    "    train_loader, val_loader, test_loader = lfw.get_data_loaders(\n",
    "        batch_size=32,\n",
    "        base_dir=paths.BASE_DATA_DIR,\n",
    "        download=False,\n",
    "        transform=transform\n",
    "    )\n",
    "\n",
    "    # Crear modelo\n",
    "    model = ConvAutoencoder().to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    # Entrenar modelo\n",
    "    train(model, train_loader, val_loader, criterion, optimizer, device, epochs=2, checkpoint_freq=5)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
